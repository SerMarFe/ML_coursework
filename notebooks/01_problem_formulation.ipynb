{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4d4f38",
   "metadata": {},
   "source": [
    "# Task 1 - Problem Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c1a09",
   "metadata": {},
   "source": [
    "__Delete this instruction cell at the end.__\n",
    "\n",
    "_This task must contain the formal problem definition (T-P-E Framework) as described in the exercise statement._\n",
    "_You can use this as a template, but make sure make any necessary modifications in case anything is missing._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fab96f3",
   "metadata": {},
   "source": [
    "## 1.1 Power Forecasting\n",
    "### Task (T)\n",
    "want a model that can look at today’s weather sensors and past power output and predict how much electricity a solar inverter will produce in the next few minutes or the next hour.\n",
    "This is a regression problem because the model predicts actual numbers (kW).\n",
    "* **Target Variable:** \n",
    "per-inverter instantaneous power (kW) and plant-level total power (sum of inverters).\n",
    "* **ML Problem Type:** \n",
    "supervised regression (single-step real-time nowcast and 1-hour ahead forecast).\n",
    "* **Prediction Horizon:**\n",
    "Nowcast / real-time: predict current (or immediate next) power using concurrent sensors (useful for short term control).\n",
    "Short horizon: 1-hour ahead (single step). If data cadence is sub-hourly, 1-hour ahead can be expressed as N steps ahead.\n",
    "* \n",
    "\n",
    "### Performance (P)\n",
    "* **Metric:** \n",
    "Primary metrics:\n",
    "\n",
    "MAE (Mean Absolute Error) — interpretable in kW (directly maps to expected energy/revenue error). Robust to outliers.\n",
    "\n",
    "RMSE (Root Mean Squared Error) — penalises large errors (important because large underestimates can cause revenue/contract penalties).\n",
    "\n",
    "Skill score vs persistence baseline (e.g., percent improvement over persistence or simple clear-sky model) — business relevant (shows value vs trivial model).\n",
    "\n",
    "Secondary metrics:\n",
    "\n",
    "sMAPE or NMAE for normalised comparisons across inverters or plants with different capacities. Avoid MAPE when values near zero (night) – will use daytime subset for MAPE.\n",
    "\n",
    "* **Justification:** ... absolute error (MAE) converts directly to lost energy (kW × time) → revenue loss; RMSE helps penalise occasional large misses that may trigger grid penalties or imbalance charges. Skill vs persistence demonstrates practical improvement.\n",
    "\n",
    "### Experience (E) - (Refer to general data description below)\n",
    "\n",
    "Available features (examples): timestamp, inverter_id, instantaneous inverter power, plant aggregate power, plant sensors (global horizontal irradiance or POA, ambient temp, module temp, wind speed, humidity), possible status flags. Derived features: sun elevation/azimuth, clear-sky irradiance, rolling lags and statistics (lags of power and irradiance, rolling mean/std), time-of-day, day-of-year, weekday/weekend.\n",
    "\n",
    "Temporal coverage & structure: 34 days — short but acceptable for short-term models; must avoid leakage and overfitting. Expect diurnal cycles and night zeros.\n",
    "\n",
    "Quality issues & pre-processing: missing timestamps, sensor dropouts, noisy irradiance (cloud spikes), outliers, intermittent inverter drops to zero. Impute short gaps (interpolation) but treat long gaps (flag and exclude or mark as missing). Remove or mask true night periods for certain metrics. Normalize per-inverter capacity.\n",
    "\n",
    "Data split (time-aware): chronological split to prevent leakage. Example split for 34 days: first 24 days train (≈70%), next 5 days validation (≈15%), final 5 days test (≈15%). Use rolling-origin validation (expanding window) for robust model selection.\n",
    "\n",
    "Baselines: persistence (last observed value), simple linear regression on irradiance & temp, and clear-sky scaled model. These are required to compute skill scores.\n",
    "\n",
    "## 1.2 Operating Condition Classification\n",
    "### Task (T)\n",
    "want to detect when an inverter is behaving abnormally — for example, producing much less power than the others.\n",
    "This is a classification problem because the model decides whether something is normal or faulty.\n",
    "* **Target Variable:** \n",
    " binary or multi-class labels indicating normal vs faulty / degraded vs maintenance required; or multi-class labels (e.g., normal, inverter fault, curtailment, communication loss, sensor fault).\n",
    "\n",
    "* **ML Problem Type:**  binary classification (fault/no fault) or multi-class classification depending on label availability. Also consider anomaly detection (unsupervised) if labelled faults are rare or absent.\n",
    "\n",
    "* **Prediction Horizon:** real-time or near-real-time detection (detect a fault within minutes/hours of occurrence).\n",
    "\n",
    "### Performance (P)\n",
    "\n",
    "Primary metrics for labelled classification:\n",
    "\n",
    "Recall (Sensitivity) — high priority to detect true faults (missing a real fault leads to lost production).\n",
    "\n",
    "Precision — to avoid excessive false alarms (which cost maintenance time and desensitize operators).\n",
    "\n",
    "F1 score — balance when single metric required.\n",
    "\n",
    "ROC-AUC and PR-AUC — PR-AUC is more informative when classes are imbalanced (faults rare).\n",
    "\n",
    "For anomaly / unsupervised methods: precision@k, false positive rate at operational thresholds, time-to-detect (latency).\n",
    "\n",
    "Business tradeoffs: typically prefer higher recall with an acceptable precision (operator can triage alarms). Tune threshold using validation to meet maintenance budget constraints.\n",
    "\n",
    "### Experience (E) -\n",
    "\n",
    "Features: short-window features per inverter (last N minutes/hours of power, normalized by clear-sky or by inverter capacity), deviation from peer inverters, residual (observed − expected from model), plant sensors, inverter telemetry if present. Peer-comparison (fleet anomaly) is very powerful: an inverter behaving differently from identical peers likely faulty.\n",
    "\n",
    "Label availability & imbalance: faults are usually rare — expect heavy class imbalance. If labels are sparse, use semi-supervised (one-class SVM, autoencoders, isolation forest) or novel approaches using peer residuals and rule-based heuristics to generate weak labels.\n",
    "\n",
    "Train/validation/test: chronological splits but ensure faults in training if supervised; if impossible, use unsupervised methods and evaluate on known labelled events (hold-out). Validation must preserve temporal order and use separate fault events than test. Use stratified selection by event rather than random sampling.\n",
    "\n",
    "Evaluation protocol: evaluate per-event (detecting the faulty window) and per-timestamp (instant detection). Report confusion matrix, PR curve, and recall at fixed precision (or precision at fixed recall) as operationally meaningful numbers.\n",
    "\n",
    "Thresholding & operationalization: calibrate decision thresholds in validation to meet an acceptable false alarm rate (e.g., < X alarms/day per plant).\n",
    "\n",
    "## 1.3 Temporal Forecasting\n",
    "### Task (T)\n",
    "predict a sequence of future power values — like the whole next hour or next day, not just one step.\n",
    "This is also regression but over multiple future time steps.\n",
    "\n",
    "Targets: sequence of future power values (per inverter and plant aggregate) for a multi-step horizon — e.g., hourly profile for next 24 hours (day-ahead) or next 6–12 steps if sampling is sub-hourly.\n",
    "\n",
    "Problem type: sequence-to-sequence regression / multi-output regression (can be framed as multi-step forecasting).\n",
    "\n",
    "Prediction horizons: multi-step (e.g., 6–96 steps depending on cadence) — where business use includes scheduling and bidding.\n",
    "\n",
    "### Performance (P)\n",
    "\n",
    "Metrics per horizon step: MAE and RMSE per forecast horizon (report progression as horizon increases).\n",
    "\n",
    "Aggregate metrics: average MAE over horizon, and energy error (kWh) over forecast window (directly maps to revenue).\n",
    "\n",
    "Skill vs naive baselines: persistence and last-day profile. For day-ahead, compare to simple climatology or clear-sky scaled profile.\n",
    "\n",
    "Coverage metrics (for probabilistic forecasts, optional): Prediction interval coverage probability (PICP) and interval width (sharpness). Probabilistic forecasts reduce exposure to uncertainty in bidding.\n",
    "\n",
    "### Experience (E) -\n",
    "\n",
    "Sequence inputs: history window (lags of power/irradiance), exogenous inputs (weather forecasts if available — very helpful for day-ahead), calendar features, sun position. For multi-step models, include deterministic features per future timestamp (sun position, forecasted irradiance if available).\n",
    "\n",
    "Model families: Seq2Seq LSTM/GRU/Transformer, temporal convolutional networks (TCN), and gradient-boosted trees trained on recursive or direct multi-output targets (e.g., LightGBM with multiple future targets).\n",
    "\n",
    "Validation: use rolling-origin (walk-forward) cross-validation: repeatedly train on days 1..t, validate on t+1..t+k to mimic production forecasting. Report averaged metrics across folds.\n",
    "\n",
    "Data sufficiency: 34 days is limited for complex deep sequence models for day-ahead generalisation; augment with physical features (clear-sky model) and strong baselines. Use careful regularisation and simpler models if overfitting observed.\n",
    "\n",
    "\n",
    "\n",
    "## 1.4 General Data Experience (E Summary)\n",
    "* **Available Features:** ...\n",
    "* **Temporal Coverage:** ...\n",
    "* **Quality Issues:** ...\n",
    "* **Splitting Strategy:** ... (e.g., Chronological 70/15/15 split)\n",
    "\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
